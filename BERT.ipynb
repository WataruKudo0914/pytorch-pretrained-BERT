{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前学習済みのベクトルを得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import run_classifier\n",
    "\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'bert_model':'bert-base-uncased',\n",
    "    'local_rank':-1,\n",
    "    'data_dir':'glue_data/ARD/',\n",
    "    'max_seq_length':128,\n",
    "    'train_batch_size':32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = run_classifier.ArdProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2018 21:43:54 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/watarukudo/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args['bert_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2018 21:43:55 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./models/pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "12/07/2018 21:43:55 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file ./models/pretrained_model_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/hn/53g2k8zj2zx2p_17pryml5zh0000gn/T/tmphtzhqh0l\n",
      "12/07/2018 21:43:58 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "12/07/2018 21:44:00 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "12/07/2018 21:44:00 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(args[\"bert_model\"],\n",
    "                cache_dir='./models/pretrained_model_{}'.format(args[\"local_rank\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = processor.get_train_examples(args[\"data_dir\"])\n",
    "\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2018 21:44:04 - INFO - run_classifier -   *** Example ***\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   guid: train-1\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   tokens: [CLS] this is an excellent camera . i have the powers ##hot a ##60 and have worked a bit with the a ##70 . the only difference on these cameras is that the a ##70 has more mega ##pi ##x ##els , other than that they are the same . the cameras offer various features , each with several different ways to manipulate the camera , including shutter speed and aperture . for the begin ##ner , it offers a few pre ##set options that allow a quick switch to the desired need of the user . the manual is very clear and easy to apply . i would recommend this camera to someone wanting a point and click camera , as well as a more advanced [SEP]\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_ids: 101 2023 2003 2019 6581 4950 1012 1045 2031 1996 4204 12326 1037 16086 1998 2031 2499 1037 2978 2007 1996 1037 19841 1012 1996 2069 4489 2006 2122 8629 2003 2008 1996 1037 19841 2038 2062 13164 8197 2595 9050 1010 2060 2084 2008 2027 2024 1996 2168 1012 1996 8629 3749 2536 2838 1010 2169 2007 2195 2367 3971 2000 17708 1996 4950 1010 2164 28180 3177 1998 18892 1012 2005 1996 4088 3678 1010 2009 4107 1037 2261 3653 13462 7047 2008 3499 1037 4248 6942 2000 1996 9059 2342 1997 1996 5310 1012 1996 6410 2003 2200 3154 1998 3733 2000 6611 1012 1045 2052 16755 2023 4950 2000 2619 5782 1037 2391 1998 11562 4950 1010 2004 2092 2004 1037 2062 3935 102\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   label: 9 (id = 9)\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   *** Example ***\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   guid: train-2\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   tokens: [CLS] thank you , ti ##vo - we are now back in control of our lives . we have been freed from fixed network time slots , commercial breaks , irritating interruption ##s , etc . there are only a few key shows i watch on a regular basis ( meet the press , the o ' reilly factor , the shield , etc . ) . pre - ti ##vo , i would find myself re - arranging my activities in order to not miss them . post - ti ##vo , i live my life and catch these shows when it ' s convenient for me . using & quo ##t ; season passes & quo ##t ; ( a ti ##vo function ) , [SEP]\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_ids: 101 4067 2017 1010 14841 6767 1011 2057 2024 2085 2067 1999 2491 1997 2256 3268 1012 2057 2031 2042 10650 2013 4964 2897 2051 19832 1010 3293 7807 1010 29348 24191 2015 1010 4385 1012 2045 2024 2069 1037 2261 3145 3065 1045 3422 2006 1037 3180 3978 1006 3113 1996 2811 1010 1996 1051 1005 13875 5387 1010 1996 6099 1010 4385 1012 1007 1012 3653 1011 14841 6767 1010 1045 2052 2424 2870 2128 1011 19018 2026 3450 1999 2344 2000 2025 3335 2068 1012 2695 1011 14841 6767 1010 1045 2444 2026 2166 1998 4608 2122 3065 2043 2009 1005 1055 14057 2005 2033 1012 2478 1004 22035 2102 1025 2161 5235 1004 22035 2102 1025 1006 1037 14841 6767 3853 1007 1010 102\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   label: 7 (id = 7)\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   *** Example ***\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   guid: train-3\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   tokens: [CLS] i give the cas ##io ex ##ili ##m z ##100 ##0 poor marks only after much thought about what a drag it is to give a negative review for such a sweet - looking camera . i researched the z ##100 ##0 before buying it . i read the few reviewers who complained about the grain ##iness of the photos at lighting conditions that were less than very , very bright , but they were over - shadowed by many more glowing reviews . i previously owned the cas ##io ex ##ili ##m ex - z ##11 ##0 6 ##mp and the photos it took were never grain ##y , even in low light . when i saw that the z ##100 ##0 had four more [SEP]\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_ids: 101 1045 2507 1996 25222 3695 4654 18622 2213 1062 18613 2692 3532 6017 2069 2044 2172 2245 2055 2054 1037 8011 2009 2003 2000 2507 1037 4997 3319 2005 2107 1037 4086 1011 2559 4950 1012 1045 18800 1996 1062 18613 2692 2077 9343 2009 1012 1045 3191 1996 2261 15814 2040 10865 2055 1996 8982 9961 1997 1996 7760 2012 7497 3785 2008 2020 2625 2084 2200 1010 2200 4408 1010 2021 2027 2020 2058 1011 25843 2011 2116 2062 10156 4391 1012 1045 3130 3079 1996 25222 3695 4654 18622 2213 4654 1011 1062 14526 2692 1020 8737 1998 1996 7760 2009 2165 2020 2196 8982 2100 1010 2130 1999 2659 2422 1012 2043 1045 2387 2008 1996 1062 18613 2692 2018 2176 2062 102\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   label: 7 (id = 7)\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   *** Example ***\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   guid: train-4\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   tokens: [CLS] i remember those point - and - shoot olympus digital cameras from mid 2000s - great images with click of a button . that ' s what i was expecting - and got disappointed . the picture quality is even worse that my old canon a ##60 ( from year 2003 ) makes . the biggest problem is - mega ##pi ##x ##els . too many . many mega ##pi ##x ##els combined with small sensor area in compact cameras result in very much noise at dark . the camera images are too noisy in any indoor environment , even at relatively low 400 iso and even with flash ! in other hand stabilize ##r is good - indoor images are sharp , but noisy . [SEP]\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_ids: 101 1045 3342 2216 2391 1011 1998 1011 5607 26742 3617 8629 2013 3054 8876 1011 2307 4871 2007 11562 1997 1037 6462 1012 2008 1005 1055 2054 1045 2001 8074 1011 1998 2288 9364 1012 1996 3861 3737 2003 2130 4788 2008 2026 2214 9330 1037 16086 1006 2013 2095 2494 1007 3084 1012 1996 5221 3291 2003 1011 13164 8197 2595 9050 1012 2205 2116 1012 2116 13164 8197 2595 9050 4117 2007 2235 13617 2181 1999 9233 8629 2765 1999 2200 2172 5005 2012 2601 1012 1996 4950 4871 2024 2205 20810 1999 2151 7169 4044 1010 2130 2012 4659 2659 4278 11163 1998 2130 2007 5956 999 1999 2060 2192 27790 2099 2003 2204 1011 7169 4871 2024 4629 1010 2021 20810 1012 102\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/07/2018 21:44:04 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   label: 9 (id = 9)\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   *** Example ***\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   guid: train-5\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   tokens: [CLS] i tried three different head ##phones : sen ##nh ##eis ##er 280 pro ##so ##und was very good , especially after some burn - in . but very uncomfortable . way to tight - - really cl ##amp down hard on your head . this produces great isolation , and they ' re well built , but this is useless if you can ' t wear them . note : i don ' t have a big head . audio tech ##nica at ##h - m3 ##0 ##the sound on these was just okay , and they sit on the ear ( not around the ear ) , so they don ' t isolate well at all . they are more comfortable than the 280 ##s [SEP]\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_ids: 101 1045 2699 2093 2367 2132 19093 1024 12411 25311 17580 2121 13427 4013 6499 8630 2001 2200 2204 1010 2926 2044 2070 6402 1011 1999 1012 2021 2200 8796 1012 2126 2000 4389 1011 1011 2428 18856 16613 2091 2524 2006 2115 2132 1012 2023 7137 2307 12477 1010 1998 2027 1005 2128 2092 2328 1010 2021 2023 2003 11809 2065 2017 2064 1005 1056 4929 2068 1012 3602 1024 1045 2123 1005 1056 2031 1037 2502 2132 1012 5746 6627 12782 2012 2232 1011 29061 2692 10760 2614 2006 2122 2001 2074 3100 1010 1998 2027 4133 2006 1996 4540 1006 2025 2105 1996 4540 1007 1010 2061 2027 2123 1005 1056 27152 2092 2012 2035 1012 2027 2024 2062 6625 2084 1996 13427 2015 102\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/07/2018 21:44:04 - INFO - run_classifier -   label: 7 (id = 7)\n"
     ]
    }
   ],
   "source": [
    "train_features = run_classifier.convert_examples_to_features(\n",
    "            train_examples, label_list, args['max_seq_length'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['local_rank'] == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args[\"train_batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 69/1250 [00:00<00:01, 686.31it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 194/1250 [00:00<00:01, 792.69it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 321/1250 [00:00<00:01, 893.37it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 454/1250 [00:00<00:00, 990.61it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 571/1250 [00:00<00:00, 1037.72it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 731/1250 [00:00<00:00, 1159.64it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 890/1250 [00:00<00:00, 1260.88it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 1034/1250 [00:00<00:00, 1308.86it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 1195/1250 [00:00<00:00, 1386.60it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 1250/1250 [00:00<00:00, 1330.57it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "batches = []\n",
    "pooled_outputs = []\n",
    "for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    batches.append(batch)\n",
    "    #input_ids, input_mask, segment_ids, label_ids = batch\n",
    "    #pooled_output = model.get_pooled_output(input_ids, segment_ids, input_mask, label_ids)\n",
    "    #pooled_outputs.append(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_mask, segment_ids, label_ids = batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 3.08 s, total: 23.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%time pooled_output = model.get_pooled_output(input_ids, segment_ids, input_mask, label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tensors = train_data.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tensors =  tuple(t.to(device) for t in train_data_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, input_mask, segment_ids, label_ids = train_data_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = model.get_pooled_output(input_ids, segment_ids, input_mask, label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklean.neural_network import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pooled_output.to_numpy()\n",
    "y = np.array(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
